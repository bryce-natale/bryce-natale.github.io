---
layout: post
title: Build Week Project ü§ì
subtitle: "Prediciting NFL Run & Pass Plays üèà"
cover-img: /assets/img/nfl3.jpg
tags: [data-science]
comments: true
---

This year has been full of the unexpected, but my favorite season is just around the corner. No, not Fall season, football season!  

Which got me to thinking, how could teams get an edge over each other during the game. 
Then it hit me, would it be possible to predict whether a team was going to run a pass or run play before the snap? 

Luckily, I found a [dataset](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016) from every play that happened in the NFL from 2009 to 2017. 
This was a reletively big dataset. It had over 100 columns and 300,000 rows, but it had everything I needed to build a model.  

Because I‚Äôm trying to predict either run or pass, we know that we will be using classification models 
such as logistic regression or any of the various tree models.  

### Let‚Äôs set the stage.  

We‚Äôll use our most common class for our baseline, which is a ‚Äúpass play‚Äù at 57%. I would have guessed that more run plays happen in the NFL but I guess the data doesn't lie. 

### The first lesson I learned: data leakage is a real thing and it‚Äôs sneaky.   

Originally I fed my model just all of the numerical data, but quickly realized something was off when my accuracy scores we‚Äôre perfect. I discovered that there were feature columns that were almost identical to the target (i.e. yards after catch). 

This is when I made the decision to switch to data that was on available before the snap of the ball.  

Ultimately I ended up with 8 features.  

- Drive - the # of times the team has had the ball in the game
- Quarter - what quarter of the game it is 
- Down - what down it is   
- Yards to go - the # of remaining yards until next 1st down 
- Yard Line - where on the field the ball is 
- Score Difference - the difference in the two teams score 
- Season - what year the game was played 
- Win Probability - how likely the team was at winning before the play 

<img src="https://bryce-natale.github.io/assets/img/Permutation Importance.png" width="300">


### Choosing a model 

While building my first model I used logistic regression, which produced slightly above baseline accuracy tests of 64% on our validation set.  

Next I wanted to see if our tree classifier would produce better results, sure enough it did. With a random forest classifier my accuracy tests jumped up to 66% accurate.  

Lastly, I used XGboost to see if I could produce even better results. Which I did but only slightly better up to 67% accurate.  

### Shapely Values 
<img src="https://bryce-natale.github.io/assets/img/Shap Values.png" width="1000"> 

### Confusion Matrix 
<img src="https://bryce-natale.github.io/assets/img/Confusion Matrix.png" width="1000"> 


### 



